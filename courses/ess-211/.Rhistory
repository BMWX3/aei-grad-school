legend('topright', legend=c('"True" runoff', 'RMSE-loss runoff', 'MAE-loss runoff'),
col=c(color_runoff, color_rmse, color_abs), lty=c(0, lty_rmse, lty_abs),
pch=c(pch_runoff))
legend('topright', legend=c('"True" runoff', 'RMSE-loss runoff', 'MAE-loss runoff'),
col=c(color_runoff, color_rmse, color_abs), lty=c(0, lty_rmse, lty_abs),
pch=c(pch_runoff, NA, NA))
?plot
stdev.P <- sd(P)
stdev.PET <- sd(PET)
# we want to iteratively add noise to P and PET from 10-200%, run opt, save the values, then repeat 10 times
noise_fraction <- seq(0.1, 2.0, by = 0.1)
n_iter <- 10
# create the output matrix to store outputs
opt_array_noise <- array(0, dim = c(3, length(noise_fraction), n_iter))
for (i in seq(1,length(noise_fraction))){
# get your normal distribution of noise for each iteration
noise.P <- rnorm(n_iter, sd = (stdev.P * noise_fraction[i]))
noise.PET <- rnorm(n_iter, sd = (stdev.PET * noise_fraction[i]))
# loop through the n iterations and try retrieving the parameters for each noise addition
for (j in seq(1, n_iter)){
# create new P and PET vectors with noise added
P_temp <- P + noise.P[j]
PET_temp <- PET + noise.PET[j]
# set negative values to zero
P_temp[P_temp < 0] = 0
PET_temp[PET_temp < 0] = 0
# run optim using the optimized parameters retrieved from the RMSE loss function.
#  that should retrieve the correct parameters under noiseless conditions, but here
#  demonstrates how noise affects retrieved parameters
opt <- optim(opt_rmse, minfunc, loss=loss.rmse, model=bucket3, y=runoff, P=P_temp,
PET=PET_temp, method='L-BFGS-B', lower=bounds.lower ,upper=bounds.upper)
# add the returned params to the matrices
opt_array_noise[, i, j] <- opt$par
}
}
opt_array_noise
plot(noise_fraction, opt_array_noise[1])
plot(noise_fraction, opt_array_noise[1,,1])
plot(noise_fraction, opt_array_noise[1,,2])
plot(noise_fraction, opt_array_noise[1,,2], col=1)
plot(noise_fraction, opt_array_noise[1,,2], col=2)
plot(noise_fraction, opt_array_noise[1,,2], col=3)
plot(noise_fraction, opt_array_noise[1,,2], col=4)
plot(noise_fraction, opt_array_noise[1,,2], col=5)
plot(noise_fraction, opt_array_noise[1,,2], col=500)
plot(noise_fraction, opt_array_noise[1,,2], col=600)
plot(noise_fraction, opt_array_noise[1,,2], col=800)
plot(noise_fraction, opt_array_noise[1,,2], col=10)
plot(noise_fraction, opt_array_noise[1,,2], col=9)
plot(noise_fraction, opt_array_noise[1,,2], col=19)
plot(noise_fraction, opt_array_noise[1,,2], col=29)
plot(noise_fraction, opt_array_noise[1,,2], col=39)
points(noise_fraction, opt_array_noise[1,,3])
plot(noise_fraction, opt_array_noise[1,,1], pch = 19, col = 1, main = title.param1,
xlab = xlab, ylab = ylab.param1, ylim = ylim.param1)
title.param1 <- "Bucket size param retrieved with added noise"
title.param2 <- "Infiltration param retrieved with added noise"
title.param3 <- "Wilt point param retrieved with added noise"
ylab.param1 <- "Bucket size"
ylab.param2 <- "Infiltration"
ylab.param3 <- "Wilt point"
xlab <- "% added noise"
# set up ylim based on min/max for each param
ylim.param1 <- c(min(opt_array_noise[1,,], na.rm = TRUE), max(opt_array_noise[1,,], na.rm = TRUE))
ylim.param2 <- c(min(opt_array_noise[2,,], na.rm = TRUE), max(opt_array_noise[2,,], na.rm = TRUE))
ylim.param3 <- c(min(opt_array_noise[3,,], na.rm = TRUE), max(opt_array_noise[3,,], na.rm = TRUE))
# output plots for each random iteration
plot(noise_fraction, opt_array_noise[1,,1], pch = 19, col = 1, main = title.param1,
xlab = xlab, ylab = ylab.param1, ylim = ylim.param1)
for (i in 2:n_iter){
points(noise_fraction, opt_array_noise[1,,i], pch = 19, col = i)
}
boxplot(noise_fraction, opt_array_noise[1,,])
?boxplot
boxplot(noise_fraction ~ opt_array_noise[1,,])
length(noise_fraction)
dim(opt_array_noise)
dim(opt_array_noise[1])
dim(opt_array_noise[1,,])
dim(t(opt_array_noise[1,,]))
boxplot(noise_fraction ~ t(opt_array_noise[1,,])
)
b <- data.frame(opt_array_noise[1,,])
View(b)
b <- data.frame(t(opt_array_noise[1,,])
)
g = paste("PCT", noise_fraction)
g
g = paste("PCT", noise_fraction * 100)
g
b <- data.frame(t(opt_array_noise[1,,]), dimnames = list(g, paste("ITER", seq(1,10))))
b <- data.frame(t(opt_array_noise[1,,]), dimnames = c(g, paste("ITER", seq(1,10))))
b <- data.frame(t(opt_array_noise[1,,]))
?data.frame
b <- data.frame(t(opt_array_noise[1,,]), row.names = g)
g
length(g)
b <- data.frame(t(opt_array_noise[1,,]), col.names = g)
b <- data.frame((opt_array_noise[1,,]), row.names = g)
boxplot(b)
boxplot(t(b))
g = paste0(noise_fraction * 100, "%")
g
b <- data.frame((opt_array_noise[1,,]), row.names = g)
boxplot(t(b))
boxplot(t(b), xlab = xlab)
boxplot(t(b), xlab = xlab, main = title.param1)
boxplot(t(b), xlab = xlab, main = title.param1, ylab = ylab.param1)
title.param1 <- "Bucket size param retrieved with added noise"
title.param2 <- "Infiltration param retrieved with added noise"
title.param3 <- "Wilt point param retrieved with added noise"
ylab.param1 <- "Bucket size"
ylab.param2 <- "Infiltration"
ylab.param3 <- "Wilt point"
xlab <- "% added noise"
# lets set up a data frame so we can create a boxplot to represent the retrieved parameters
df.param1 <- data.frame(opt_array_noise[1,,], row.names = paste0(noise_fraction * 100, "%"))
df.param2 <- data.frame(opt_array_noise[2,,], row.names = paste0(noise_fraction * 100, "%"))
df.param3 <- data.frame(opt_array_noise[3,,], row.names = paste0(noise_fraction * 100, "%"))
boxplot(t(df.param1), xlab = xlab, ylab = ylab.param1, main = title.param1)
boxplot(t(df.param2), xlab = xlab, ylab = ylab.param2, main = title.param2)
boxplot(t(df.param3), xlab = xlab, ylab = ylab.param3, main = title.param3)
boxplot(t(df.param1), xlab = xlab, ylab = ylab.param1, main = title.param1, las = 2)
boxplot(t(df.param2), xlab = xlab, ylab = ylab.param2, main = title.param2, las = 2)
boxplot(t(df.param3), xlab = xlab, ylab = ylab.param3, main = title.param3, las = 2)
stdev.runoff <- sd(runoff)
for (i in seq(1,length(noise_fraction))){
# get your normal distribution of noise for each iteration
noise.runoff <- rnorm(n_iter, sd = (stdev.runoff * noise_fraction[i]))
# loop through the n iterations and try retrieving the parameters for each noise addition
for (j in seq(1, n_iter)){
# create new P and PET vectors with noise added
runoff_temp <- runoff + noise.P[j]
# set negative values to zero
runoff_temp[runoff_temp < 0] = 0
# run optim using the optimized parameters retrieved from the RMSE loss function.
#  that should retrieve the correct parameters under noiseless conditions, but here
#  demonstrates how noise affects retrieved parameters. This time, noisy 'truth' data
opt <- optim(opt_rmse, minfunc, loss=loss.rmse, model=bucket3, y=runoff_temp, P=P,
PET=PET, method='L-BFGS-B', lower=bounds.lower ,upper=bounds.upper)
# add the returned params to the matrices
opt_array_noise[, i, j] <- opt$par
}
}
# lets set up a data frame so we can create a boxplot to represent the retrieved parameters
df.param1 <- data.frame(opt_array_noise[1,,], row.names = paste0(noise_fraction * 100, "%"))
df.param2 <- data.frame(opt_array_noise[2,,], row.names = paste0(noise_fraction * 100, "%"))
df.param3 <- data.frame(opt_array_noise[3,,], row.names = paste0(noise_fraction * 100, "%"))
# create box plots for each parameter
boxplot(t(df.param1), xlab = xlab, ylab = ylab.param1, main = title.param1, las = 2)
runoff_temp
runoff
noise.runoff
runoff
noise.P
stdev.runoff
noise_fraction[i]
noise.runoff[i]
i
noise.runoff
noise.runoff[j]
for (i in seq(1,length(noise_fraction))){
# get your normal distribution of noise for each iteration
noise.runoff <- rnorm(n_iter, sd = (stdev.runoff * noise_fraction[i]))
# loop through the n iterations and try retrieving the parameters for each noise addition
for (j in seq(1, n_iter)){
# create new P and PET vectors with noise added
runoff_temp <- runoff + noise.runoff[j]
# set negative values to zero
runoff_temp[runoff_temp < 0] = 0
# run optim using the optimized parameters retrieved from the RMSE loss function.
#  that should retrieve the correct parameters under noiseless conditions, but here
#  demonstrates how noise affects retrieved parameters. This time, noisy 'truth' data
opt <- optim(opt_rmse, minfunc, loss=loss.rmse, model=bucket3, y=runoff_temp, P=P,
PET=PET, method='L-BFGS-B', lower=bounds.lower ,upper=bounds.upper)
# add the returned params to the matrices
opt_array_noise[, i, j] <- opt$par
}
}
# lets set up a data frame so we can create a boxplot to represent the retrieved parameters
df.param1 <- data.frame(opt_array_noise[1,,], row.names = paste0(noise_fraction * 100, "%"))
df.param2 <- data.frame(opt_array_noise[2,,], row.names = paste0(noise_fraction * 100, "%"))
df.param3 <- data.frame(opt_array_noise[3,,], row.names = paste0(noise_fraction * 100, "%"))
# create box plots for each parameter
boxplot(t(df.param1), xlab = xlab, ylab = ylab.param1, main = title.param1, las = 2)
boxplot(t(df.param2), xlab = xlab, ylab = ylab.param2, main = title.param2, las = 2)
boxplot(t(df.param3), xlab = xlab, ylab = ylab.param3, main = title.param3, las = 2)
setwd("~/src/aei-grad-school/courses/ess-211/")
# this functions file contains bucket1, bucket3, and the loss functions
source("ESS-211-Functions.R")
# load the provided P, PET, and runoff data
load('course_material/runoff.Rdata')
#############################
# task 1 - finding parameters for bucket3 using runoff data
# first, set the upper and lower bounds of the parameters for infilt and wilt
#  bucket size range 0-200 based on in-class examples
#  infiltration ranges 0-0.5
#  wilting point ranges 0-0.5
bounds.lower <- c(0.001, 0, 0)
bounds.upper <- c(200, 0.5, 0.5)
# in order to find our parameters, we'll randomly set par0 by sampling
#  the upper and lower bounds using a uniform distribution
# set the number of iterations to try
n_searches <- 100
# create a vector for bucket size, min infilt and wilt point
random.bucket <- runif(n_searches, min = bounds.lower[1], max = bounds.upper[1])
random.infilt <- runif(n_searches, min = bounds.lower[2], max = bounds.upper[2])
random.wilt <- runif(n_searches, min = bounds.lower[3], max = bounds.upper[3])
# create a matrix to store the outputs from each parameter run
opt_matrix <- matrix(nrow = n_searches, ncol = 3)
# report starting
print("Beginning parameter search for bucket3 function")
# run the optimization on series of initial parameter guesses
for (i in seq(1,n_searches)){
# set par0 equal to the randomly assigned starting parameters
par0 <- c(random.bucket[i], random.infilt[i], random.wilt[i])
# run the optimization for these parameters
opt <- optim(par0, minfunc, loss=loss.rmse, model=bucket3, y=runoff, P=P,
PET=PET, method='L-BFGS-B', lower=bounds.lower ,upper=bounds.upper)
# assign the output params to the storage matrix
opt_matrix[i,] <- opt$par
# and report the values for each iteration
print(opt$par)
}
# the values retrieved from this optimization vary substantially, but each
#  optimized parameter has an approximately normal distribution. will round
#  the outputs to a few digits and look for the modal value returned
modal.bucket.rmse <- mode(round(opt_matrix[,1], digits = 1))
modal.infilt.rmse <- mode(round(opt_matrix[,2], digits = 2))
modal.wilt.rmse <- mode(round(opt_matrix[,3], digits = 2))
# report the retrieved optimized parameters
#  should be ~ 112, 0.23, 0.15
print(paste("Optimized RMSE parameters for bucket 3:", modal.bucket.rmse, modal.infilt.rmse, modal.wilt.rmse))
opt_rmse <- c(modal.bucket.rmse, modal.infilt.rmse, modal.wilt.rmse)
hist(opt_matrix[,1])
hist(opt_matrix[,1], breaks = 20)
hist(opt_matrix[,1], breaks = seq(min(opt_matrix[,1]), max(opt_matrix[,1]), by=5))
hist(opt_matrix[,1], breaks = seq(min(opt_matrix[,1])-5, max(opt_matrix[,1])+5, by=5))
hist(opt_matrix[,1], breaks = seq(min(opt_matrix[,1])-5, max(opt_matrix[,1])+5, by=5), xlab = "Retrieved value of full.bucket", main = "Histogram of full.bucket retrieved parameter")
hist(opt_matrix[,1], breaks = seq(min(opt_matrix[,1])-5, max(opt_matrix[,1])+5, by=5), xlab = "Retrieved value of full.bucket", main = "Distribution of full.bucket retrieved parameters", col='light blue')
hist(opt_matrix[,1], breaks = seq(min(opt_matrix[,1])-5, max(opt_matrix[,1])+5, by=5), xlab = "Retrieved value of full.bucket", main = "Distribution of full.bucket retrieved parameters", col='light blue', las=2)
hist(opt_matrix[,1], breaks = seq(min(opt_matrix[,1])-5, max(opt_matrix[,1])+5, by=5), xlab = "Retrieved value of full.bucket", main = "Distribution of full.bucket retrieved parameters", col='light blue', las=1)
# perform the same calibration process, but using mean absolute error for the loss function
for (i in seq(1,n_searches)){
# set par0 equal to the randomly assigned starting parameters
par0 <- c(random.bucket[i], random.infilt[i], random.wilt[i])
# run the optimization for these parameters
opt <- optim(par0, minfunc, loss=loss.abs, model=bucket3, y=runoff, P=P,
PET=PET, method='L-BFGS-B', lower=bounds.lower ,upper=bounds.upper)
# assign the output params to the storage matrix
opt_matrix[i,] <- opt$par
# and report the values for each iteration
print(opt$par)
}
# find the modal values from using mean absolute error loss function
modal.bucket.abs <- mode(round(opt_matrix[,1], digits = 1))
modal.infilt.abs <- mode(round(opt_matrix[,2], digits = 2))
modal.wilt.abs <- mode(round(opt_matrix[,3], digits = 2))
# report parameters
print(paste("Optimized MAE parameters for bucket 3:", modal.bucket.abs, modal.infilt.abs, modal.wilt.abs))
opt_abs <- c(modal.bucket.abs, modal.infilt.abs, modal.wilt.abs)
# calculate the runoff values for the different optimizations
runoff_rmse <- bucket3(opt_rmse, P, PET)
runoff_abs <- bucket3(opt_abs, P, PET)
# if I got the parameters correct above, the rmse and mean of absolute errors should be 0
print(paste("Root mean squared error:", loss.rmse(runoff, runoff_rmse)))
print(paste("Mean of absolute error :", loss.abs(runoff, runoff_abs)))
# set the y axis min/max
ymin <- min(runoff, runoff_rmse, runoff_abs)
ymax <- max(runoff, runoff_rmse, runoff_abs)
ylim <- c(ymin, ymax)
# set the labels
title <- "Comparing runoff with optimized parameters"
xlab <- "Time step"
ylab <- "Runoff (units)"
# set line and color params
pch_runoff <- 19
lty_rmse <- 2
lty_abs <- 1
color_runoff <- 'green'
color_rmse <- 'black'
color_abs <- 'orange'
# plot the runoff values for each simulation
plot(runoff, ylim = ylim, main = title, xlab = xlab, ylab = ylab, pch = pch_runoff, col = color_runoff)
lines(runoff_abs, lty = lty_abs, col = color_abs)
lines(runoff_rmse, lty = lty_rmse, col = color_rmse)
# add the legend
legend('topright', legend=c('"True" runoff', 'RMSE-loss runoff', 'MAE-loss runoff'),
col=c(color_runoff, color_rmse, color_abs), lty=c(0, lty_rmse, lty_abs),
pch=c(pch_runoff, NA, NA))
mean(opt_matrix[,1])
sd(opt_matrix[,1])
sd(opt_matrix[,2])
mean(opt_matrix[,2])
sd(opt_matrix[,3])
mean(opt_matrix[,3])
ylab <- "Runoff"
plot(runoff, ylim = ylim, main = title, xlab = xlab, ylab = ylab, pch = pch_runoff, col = color_runoff)
lines(runoff_abs, lty = lty_abs, col = color_abs)
lines(runoff_rmse, lty = lty_rmse, col = color_rmse)
pch=c(pch_runoff, NA, NA))
legend('topright', legend=c('"True" runoff', 'RMSE-loss runoff', 'MAE-loss runoff'),
col=c(color_runoff, color_rmse, color_abs), lty=c(0, lty_rmse, lty_abs),
pch=c(pch_runoff, NA, NA))
opt_matrix <- matrix(nrow = n_searches, ncol = 3)
# report starting
print("Beginning parameter search for bucket3 function")
# run the optimization on series of initial parameter guesses
for (i in seq(1,n_searches)){
# set par0 equal to the randomly assigned starting parameters
par0 <- c(random.bucket[i], random.infilt[i], random.wilt[i])
# run the optimization for these parameters
opt <- optim(par0, minfunc, loss=loss.rmse, model=bucket3, y=runoff, P=P,
PET=PET, method='L-BFGS-B', lower=bounds.lower ,upper=bounds.upper)
# assign the output params to the storage matrix
opt_matrix[i,] <- opt$par
# and report the values for each iteration
print(opt$par)
}
sd(opt_matrix[,1])
sd(opt_matrix[,2])
sd(opt_matrix[,3])
g = bucket3(120, .53, .2)
g = bucket3(c(120, .53, .2), P, PET)
g
rmse(runoff,g)
loss.rmse(runoff,g)
los.abs(runoff,g)
loss.abs(runoff,g)
?loss
?optime
?optim
stdev.P <- sd(P)
stdev.PET <- sd(PET)
# we want to iteratively add noise to P and PET from 10-200%, run opt, save the values, then repeat 10 times
noise_fraction <- seq(0.1, 2.0, by = 0.1)
n_iter <- 10
# create the output matrix to store outputs
opt_array_noise <- array(0, dim = c(3, length(noise_fraction), n_iter))
for (i in seq(1,length(noise_fraction))){
# get your normal distribution of noise for each iteration
noise.P <- rnorm(n_iter, sd = (stdev.P * noise_fraction[i]))
noise.PET <- rnorm(n_iter, sd = (stdev.PET * noise_fraction[i]))
# loop through the n iterations and try retrieving the parameters for each noise addition
for (j in seq(1, n_iter)){
# create new P and PET vectors with noise added
P_temp <- P + noise.P[j]
PET_temp <- PET + noise.PET[j]
# set negative values to zero
P_temp[P_temp < 0] = 0
PET_temp[PET_temp < 0] = 0
# run optim using the optimized parameters retrieved from the RMSE loss function.
#  that should retrieve the correct parameters under noiseless conditions, but here
#  demonstrates how noise affects retrieved parameters
opt <- optim(opt_rmse, minfunc, loss=loss.rmse, model=bucket3, y=runoff, P=P_temp,
PET=PET_temp, method='L-BFGS-B', lower=bounds.lower ,upper=bounds.upper)
# add the returned params to the matrices
opt_array_noise[, i, j] <- opt$par
}
}
# now that we have generated info for n iterations at varying levels of noise, plot the
#  output parameters (so, for bucket3, each of the 3 parameters)
# first set up plot titles
title.param1 <- "Bucket size param retrieved with added noise"
title.param2 <- "Infiltration param retrieved with added noise"
title.param3 <- "Wilt point param retrieved with added noise"
ylab.param1 <- "Bucket size"
ylab.param2 <- "Infiltration"
ylab.param3 <- "Wilt point"
xlab <- "% added noise"
# lets set up a data frame so we can create a boxplot to represent the retrieved parameters
df.param1 <- data.frame(opt_array_noise[1,,], row.names = paste0(noise_fraction * 100, "%"))
df.param2 <- data.frame(opt_array_noise[2,,], row.names = paste0(noise_fraction * 100, "%"))
df.param3 <- data.frame(opt_array_noise[3,,], row.names = paste0(noise_fraction * 100, "%"))
par(mfcol=3)
par(mfcol=c(1,3)
)
boxplot(t(df.param1), xlab = xlab, ylab = ylab.param1, main = title.param1, las = 2)
boxplot(t(df.param2), xlab = xlab, ylab = ylab.param2, main = title.param2, las = 2)
boxplot(t(df.param3), xlab = xlab, ylab = ylab.param3, main = title.param3, las = 2)
par(mfcol=3)
par(mfcol=c(1,3))
boxplot(t(df.param1), xlab = xlab, ylab = ylab.param1, main = title.param1, las = 2, col='orange')
boxplot(t(df.param2), xlab = xlab, ylab = ylab.param2, main = title.param2, las = 2, col='green')
boxplot(t(df.param3), xlab = xlab, ylab = ylab.param3, main = title.param3, las = 2, col='salmon')
par(mfcol=c(1,3))
boxplot(t(df.param1), xlab = xlab, ylab = ylab.param1, main = title.param1, las = 2, col='orange')
boxplot(t(df.param2), xlab = xlab, ylab = ylab.param2, main = title.param2, las = 2, col='light green')
boxplot(t(df.param3), xlab = xlab, ylab = ylab.param3, main = title.param3, las = 2, col='salmon')
# add noise based on standard deviation
stdev.runoff <- sd(runoff)
for (i in seq(1,length(noise_fraction))){
# get your normal distribution of noise for each iteration
noise.runoff <- rnorm(n_iter, sd = (stdev.runoff * noise_fraction[i]))
# loop through the n iterations and try retrieving the parameters for each noise addition
for (j in seq(1, n_iter)){
# create new P and PET vectors with noise added
runoff_temp <- runoff + noise.runoff[j]
# set negative values to zero
runoff_temp[runoff_temp < 0] = 0
# run optim using the optimized parameters retrieved from the RMSE loss function.
#  that should retrieve the correct parameters under noiseless conditions, but here
#  demonstrates how noise affects retrieved parameters. This time, noisy 'truth' data
opt <- optim(opt_rmse, minfunc, loss=loss.rmse, model=bucket3, y=runoff_temp, P=P,
PET=PET, method='L-BFGS-B', lower=bounds.lower ,upper=bounds.upper)
# add the returned params to the matrices
opt_array_noise[, i, j] <- opt$par
}
}
# lets set up a data frame so we can create a boxplot to represent the retrieved parameters
df.param1 <- data.frame(opt_array_noise[1,,], row.names = paste0(noise_fraction * 100, "%"))
df.param2 <- data.frame(opt_array_noise[2,,], row.names = paste0(noise_fraction * 100, "%"))
df.param3 <- data.frame(opt_array_noise[3,,], row.names = paste0(noise_fraction * 100, "%"))
par(mfcol=c(1,3))
boxplot(t(df.param1), xlab = xlab, ylab = ylab.param1, main = title.param1, las = 2, col = 'orange')
boxplot(t(df.param2), xlab = xlab, ylab = ylab.param2, main = title.param2, las = 2, col = 'light green')
boxplot(t(df.param3), xlab = xlab, ylab = ylab.param3, main = title.param3, las = 2, col = 'salmon')
# create a matrix to store the outputs from each parameter run
opt_matrix <- matrix(nrow = n_searches, ncol = 3)
# report starting
print("Beginning parameter search for bucket3 function")
# run the optimization on series of initial parameter guesses
for (i in seq(1,n_searches)){
# set par0 equal to the randomly assigned starting parameters
par0 <- c(random.bucket[i], random.infilt[i], random.wilt[i])
# run the optimization for these parameters
opt <- optim(par0, minfunc, loss=loss.rmse, model=bucket3, y=runoff, P=P,
PET=PET, method='L-BFGS-B', lower=bounds.lower ,upper=bounds.upper)
# assign the output params to the storage matrix
opt_matrix[i,] <- opt$par
# and report the values for each iteration
print(opt$par)
}
hist(opt_matrix[,1], breaks = seq(min(opt_matrix[,1])-5, max(opt_matrix[,1])+5, by=5), xlab = "Retrieved value of full.bucket", main = "Distribution of full.bucket retrieved parameters", col='light blue', las=1)
hist(opt_matrix[,2], breaks = seq(min(opt_matrix[,2])-5, max(opt_matrix[,2])+5, by=5), xlab = "Retrieved value of min.infilt", main = "min.infilt", col='light blue', las=1)
hist(opt_matrix[,2], breaks = seq(0,0.5, by=0.05), xlab = "Retrieved value of min.infilt", main = "min.infilt", col='light blue', las=1)
hist(opt_matrix[,1], breaks = seq(min(opt_matrix[,1])-5, max(opt_matrix[,1])+5, by=5), xlab = "Retrieved value of full.bucket", main = "full.bucket", col='light blue', las=1)
hist(opt_matrix[,2], breaks = seq(0,0.5, by=0.05), xlab = "Retrieved value of min.infilt", main = "min.infilt", col='light blue', las=1)
hist(opt_matrix[,1], breaks = seq(min(opt_matrix[,1])-5, max(opt_matrix[,1])+5, by=5), xlab = "Retrieved value of full.bucket", main = "full.bucket", col='light blue', las=1)
hist(opt_matrix[,1], breaks = seq(min(opt_matrix[,1])-5, max(opt_matrix[,1])+5, by=5), xlab = "Retrieved value of full.bucket", main = "full.bucket", col='light blue', las=1)
hist(opt_matrix[,2], breaks = seq(0,0.5, by=0.05), xlab = "Retrieved value of min.infilt", main = "min.infilt", col='light green', las=1)
hist(opt_matrix[,3], breaks = seq(0,0.5, by=0.05), xlab = "Retrieved value of wilt.point", main = "wilt.point", col='salmon', las=1)
hist(opt_matrix[,1], breaks = seq(0,200, by=20), xlab = "Retrieved value of full.bucket", main = "full.bucket", col='light blue', las=1)
hist(opt_matrix[,2], breaks = seq(0,0.5, by=0.05), xlab = "Retrieved value of min.infilt", main = "min.infilt", col='light green', las=1)
hist(opt_matrix[,3], breaks = seq(0,0.5, by=0.05), xlab = "Retrieved value of wilt.point", main = "wilt.point", col='salmon', las=1)
hist(opt_matrix[,1], breaks = seq(0,200, by=20), xlab = "Retrieved value of full.bucket", main = "full.bucket", col='orange', las=1)
hist(opt_matrix[,2], breaks = seq(0,0.5, by=0.05), xlab = "Retrieved value of min.infilt", main = "min.infilt", col='light green', las=1)
hist(opt_matrix[,3], breaks = seq(0,0.5, by=0.05), xlab = "Retrieved value of wilt.point", main = "wilt.point", col='salmon', las=1)
setwd("~/src/aei-grad-school/courses/ess-211/")
# load ESS-211 functions
source("ESS-211-Functions.R")
# load the raw data to a data frame
enlistmint <- read.csv('demilitarization_project/Enlistment.csv', row.names = 1, header = TRUE)
demographics <- read.csv('demilitarization_project/Demographics.csv', row.names = 1, header = TRUE)
yearly <- read.csv('demilitarization_project/YearlyData.csv', row.names = 1, header = TRUE)
View(demographics)
demographics$Army
demographics$Navy
demographics$Army[OfficerEnlistedRatio]
demographics$Army['OfficerEnlistedRatio']
demographics['RaceBlack']
g = row.names(demographics)
g
demographics[g[0]]
demographics$Army[g[0]]
g[0]
g
g[1]
demographics$Army[g[1]]
demographics$Army[g[3]]
demographics$Army[g[3],]
g[3]
demographics[g[3],]
demographics[g[3],]$Army
b <- demographics[g[3]]$Navy
b <- demographics[g[3]]$Navy[1]
b <- demographics[g[3],]$Navy[1]
b
b <- demographics[g[3],1]$Navy[1]
b <- demographics[g[3],1]$Navy
b <- demographics[g[3],]$Navy
b
b[1]
View(demographics)
View(enlistmint)
enlistmint <- read.csv('demilitarization_project/Enlistment.csv', header = TRUE)
demographics <- read.csv('demilitarization_project/Demographics.csv', header = TRUE)
View(yearly)
demographics <- read.csv('demilitarization_project/Demographics.csv', row.names = 1, header = TRUE)
yearly <- read.csv('demilitarization_project/YearlyData.csv', header = TRUE)
View(yearly)
cols <- rep("", length(yearly))
cols <- rep("", nrow(yearly))
barplot(yearly$nConflicts, col = cols)
cols[yearly$PresidentialParty == "Republican"] = "Red"
cols[yearly$PresidentialParty == "Democrat"] = "Blue"
barplot(yearly$nConflicts, col = cols)
?barplot
ylab <- "Number of Unique Conflicts"
xlab <- "Year"
title <- "Unique Conflicts by Presidential Party"
barplot(yearly$nConflicts, col = cols, names.arg = yearly$Year, ylab = ylab, xlab = xlab, main = title)
plot(yearly$nConflicts, col = cols, names.arg = yearly$Year, ylab = ylab, xlab = xlab, main = title)
barplot(yearly$nConflicts, col = cols, names.arg = yearly$Year, ylab = ylab, xlab = xlab, main = title)
title <- "Unique Conflicts Per Year"
barplot(yearly$nConflicts, col = cols, names.arg = yearly$Year, ylab = ylab, xlab = xlab, main = title)
title <- "Unique Military Conflicts Per Year"
barplot(yearly$nConflicts, col = cols, names.arg = yearly$Year, ylab = ylab, xlab = xlab, main = title)
yearly <- read.csv('demilitarization_project/YearlyData.csv', header = TRUE)
barplot(yearly$nConflicts, col = cols, names.arg = yearly$Year, ylab = ylab, xlab = xlab, main = title)
?boxplot
boxplot(yearly$nConflicts)
